{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing Packages\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.preprocessing as skp\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.4\n"
     ]
    }
   ],
   "source": [
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object Creation\n",
    "dataset = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Dataset\n",
    "(X_train, Y_train), (X_test, Y_test) = dataset.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing Train-Data & Test-Data\n",
    "X_train = keras.utils.normalize(X_train,axis=1)\n",
    "X_test = keras.utils.normalize(X_test,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,) (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, Y_train.shape, X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flattening & Reshaping The Numpy Arrays \n",
    "X_train = X_train.flatten().reshape(60000,784)\n",
    "X_test = X_test.flatten().reshape(10000,784)\n",
    "Y_train = Y_train.reshape(60000,1).astype('float32')\n",
    "Y_test = Y_test.reshape(10000,1).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d483c060b8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting Image Of any Random digit\n",
    "plt.imshow(X_train[47].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneHot Encoding Y-train & Y_test\n",
    "Enc = OneHotEncoder(sparse = False, categories = 'auto')\n",
    "Y_train = Enc.fit_transform(Y_train)\n",
    "Y_test = Enc.fit_transform(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_Net:\n",
    "    # Initializing Weights & Biases\n",
    "    def __init__(self, Input_nodes, Hidden_nodes, Output_nodes):\n",
    "        self.W_0_1 = np.random.normal(0,1,(Hidden_nodes, Input_nodes))\n",
    "        self.B_0_1 = np.random.normal(0,1,(Hidden_nodes,1))\n",
    "        self.W_1_2 = np.random.normal(0,1,(Output_nodes, Hidden_nodes))\n",
    "        self.B_1_2 = np.random.normal(0,1,(Output_nodes, 1))\n",
    "    \n",
    "    # Calculating value of sigmoid\n",
    "    def Sigmoid(self, Z):\n",
    "        return (1/(1+(np.exp(-Z))))\n",
    "    \n",
    "    # Calculating value of softmax\n",
    "    def Softmax(self, Z):\n",
    "        return ((np.exp(Z))/(np.exp(Z).sum()))\n",
    "    \n",
    "    # Predicting Values for a 2 Layer Neural Network (1 Hidden Layer + Output Layer)\n",
    "    def Predict(self, X):\n",
    "        self.Z1 = (self.W_0_1 @ X.T) + self.B_0_1\n",
    "        self.A1 = self.Sigmoid(self.Z1)\n",
    "        self.Z2 = (self.W_1_2 @ self.A1) + self.B_1_2\n",
    "        self.A2 = self.Softmax(self.Z2)\n",
    "        return self.A2.T\n",
    "    \n",
    "    # Training The Network for 2 Layer\n",
    "    def Train(self, X_train, Y_train, Epochs, Batch_size, Alpha):\n",
    "        e = Epochs\n",
    "        while e>0:\n",
    "            itr = (X_train.shape[0]) // Batch_size\n",
    "            for i in range(itr):\n",
    "                # Forward Propogation\n",
    "                X = X_train[(Batch_size*i):(Batch_size*(i+1))]\n",
    "                Y = Y_train[(Batch_size*i):(Batch_size*(i+1))].T\n",
    "                self.Z1 =  (self.W_0_1 @ (X.T)) + self.B_0_1\n",
    "                self.A1 = self.Sigmoid(self.Z1)\n",
    "                self.Z2 = (self.W_1_2 @ self.A1) + self.B_1_2\n",
    "                self.A2 = self.Softmax(self.Z2)\n",
    "                \n",
    "                self.A1_t = self.A1.T\n",
    "                self.A2_t = self.A2.T\n",
    "                \n",
    "                if i == 0:\n",
    "                    Predictions = np.array(self.A2_t)\n",
    "                else:\n",
    "                    Predictions = np.vstack((Predictions,self.A2_t))\n",
    "                \n",
    "                # Loss Calculation\n",
    "                L = (Y.T * np.log(self.A2_t)).sum()\n",
    "                Loss = -(1/Batch_size) * L\n",
    "                    \n",
    "                # Calculate Gradients\n",
    "                dloss_B_1_2 = -(Y * (1 - self.A2))\n",
    "                dloss_W_1_2 = dloss_B_1_2 @ self.A1.T\n",
    "                dloss_B_0_1 = ((dloss_B_1_2.T @ self.W_1_2) * self.A1_t * (1 - self.A1_t)).T\n",
    "                dloss_W_0_1 = dloss_B_0_1 @ X\n",
    "                    \n",
    "                # Backpropogation\n",
    "                self.W_0_1 = self.W_0_1 - Alpha * dloss_W_0_1\n",
    "                self.B_0_1 = self.B_0_1 - Alpha * dloss_B_0_1\n",
    "                self.W_1_2 = self.W_1_2 - Alpha * dloss_W_1_2\n",
    "                self.B_1_2 = self.B_1_2 - Alpha * dloss_B_1_2\n",
    "                            \n",
    "            # Calculate Overall Loss\n",
    "            L_train = (Y_train * np.log(Predictions)).sum()\n",
    "            Train_loss = -(1/Y_train.shape[0]) * L_train\n",
    "            \n",
    "            Y_train_Orig = np.argmax(Y_train, axis=1)\n",
    "            Y_train_Predict = np.argmax(Predictions, axis=1)\n",
    "            \n",
    "            print(\"Epoch\",Epochs-e+1,\"    loss:\",Loss,\"    accuracy:\",accuracy_score(Y_train_Orig,Y_train_Predict), \"\\n\")\n",
    "            \n",
    "            e = e - 1\n",
    "    \n",
    "    # Testing the Neural Network\n",
    "    def Test(self, X_test, Y_test, Batch_size):\n",
    "        itr = (X_test.shape[0]) // Batch_size\n",
    "        for i in range(itr):\n",
    "            X = X_test[(Batch_size*i):(Batch_size*(i+1))]\n",
    "            Y_pred = self.Predict(X)\n",
    "            \n",
    "            if i == 0:\n",
    "                Y_predicted = np.array(Y_pred)\n",
    "            else:\n",
    "                Y_predicted = np.vstack((Y_predicted,Y_pred))\n",
    "        \n",
    "        L_test = (Y_test * np.log(Y_predicted)).sum()\n",
    "        Test_loss = -(1/Y_test.shape[0]) * L_test\n",
    "        \n",
    "        Y_test_Orig = np.argmax(Y_test, axis=1)\n",
    "        Y_test_Predict = np.argmax(Y_predicted, axis=1)\n",
    "        \n",
    "        print(classification_report(Y_test_Orig,Y_test_Predict))\n",
    "        print(confusion_matrix(Y_test_Orig,Y_test_Predict))\n",
    "        print(\"loss:\",Test_loss, \"accuracy:\",accuracy_score(Y_test_Orig,Y_test_Predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the number of nodes in input layer: 784\n",
      "Enter the number of nodes in 1st hidden layer: 256\n",
      "Enter the number of nodes in output layer: 10\n",
      "Enter the number of epochs: 3\n",
      "Enter the batch size: 1\n",
      "Enter the learning rate: 0.0001\n"
     ]
    }
   ],
   "source": [
    "# Taking Input From User\n",
    "I_nodes = int(input(\"Enter the number of nodes in input layer: \"))\n",
    "H_nodes = int(input(\"Enter the number of nodes in 1st hidden layer: \"))\n",
    "O_nodes = int(input(\"Enter the number of nodes in output layer: \"))\n",
    "E = int(input(\"Enter the number of epochs: \"))\n",
    "B_size = int(input(\"Enter the batch size: \"))\n",
    "Learning_rate = float(input(\"Enter the learning rate: \"))\n",
    "NN = Neural_Net(I_nodes, H_nodes, O_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1     loss: 8.969671845724356     accuracy: 0.13695 \n",
      "\n",
      "Epoch 2     loss: 9.92350691443361     accuracy: 0.32776666666666665 \n",
      "\n",
      "Epoch 3     loss: 8.491644460525354     accuracy: 0.4568 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "NN.Train(X_train, Y_train, E, B_size, Learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.47      0.62       980\n",
      "           1       0.92      0.53      0.68      1135\n",
      "           2       0.30      0.50      0.38      1032\n",
      "           3       0.29      0.56      0.39      1010\n",
      "           4       0.53      0.48      0.51       982\n",
      "           5       0.60      0.45      0.51       892\n",
      "           6       0.78      0.50      0.61       958\n",
      "           7       0.61      0.54      0.57      1028\n",
      "           8       0.33      0.44      0.37       974\n",
      "           9       0.58      0.46      0.51      1009\n",
      "\n",
      "   micro avg       0.50      0.50      0.50     10000\n",
      "   macro avg       0.59      0.49      0.52     10000\n",
      "weighted avg       0.59      0.50      0.52     10000\n",
      "\n",
      "[[460   0 206 198  12  39  15   8  24  18]\n",
      " [  0 605  64 187   6   9   0   1 263   0]\n",
      " [  6  13 521 189  62   9   9  12 201  10]\n",
      " [  5   2 194 570   6  48   2  22 160   1]\n",
      " [  1   1  84 137 475  29  66  34  20 135]\n",
      " [ 17   4  94 161  41 397  12  34 111  21]\n",
      " [  7  22  81 216 100  15 478  19  15   5]\n",
      " [  1   3 164  56  41  24  15 553  59 112]\n",
      " [  2   7 174 152  31  57   6  85 430  30]\n",
      " [  3   0 130  85 115  33   9 132  37 465]]\n",
      "loss: 2.6545505152771227 accuracy: 0.4954\n"
     ]
    }
   ],
   "source": [
    "NN.Test(X_test, Y_test, B_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
